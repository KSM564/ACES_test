{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d65e23-32a6-4ccb-bd1d-3f98e903ee29",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8eafdc-a187-4375-a685-9a40c60aa7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: absl-py in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from mediapipe) (3.10.3)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from mediapipe) (4.25.8)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from jax->mediapipe) (0.5.3)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from jax->mediapipe) (1.15.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->mediapipe) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->mediapipe) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f3d66c7-c298-42e6-9a6e-0ebf6f704c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ec448d-494d-44d4-90d3-04832d49d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIDEO FEED\n",
    "cap = cv2.VideoCapture(0) #webcam src\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read() #live image feed\n",
    "    cv2.imshow('Mediapipe Feed', frame) #feed visualisation\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'): #close feed command\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92941801-efcd-4891-b8bc-b208a65d1c01",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae065f7-9672-494e-b0b4-01c3e0c5374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5 , min_tracking_confidence=0.5) as pose: #min confidence = accuracy, more accuracy = more difficult to track\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #recolour image to RGB\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image) #make detection\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) #recolour image to BGR\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,                 #detection rendering\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),  #rendering landmark\n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)   #rendering landmark\n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9740ddfc-20f6-4822-be06-4f28d9cb22ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mmp_drawing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDrawingSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mthickness\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcircle_radius\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      DrawingSpec(color: Tuple[int, int, int] = (224, 224, 224), thickness: int = 2, circle_radius: int = 2)\n",
       "\u001b[1;31mSource:\u001b[0m        \n",
       "\u001b[1;33m@\u001b[0m\u001b[0mdataclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;32mclass\u001b[0m \u001b[0mDrawingSpec\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[1;31m# Color for drawing the annotation. Default to the white color.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWHITE_COLOR\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[1;31m# Thickness for drawing the annotation. Default to 2 pixels.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[0mthickness\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[1;31m# Circle radius. Default to 2 pixels.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[0mcircle_radius\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\karth\\anaconda3\\envs\\py310\\lib\\site-packages\\mediapipe\\python\\solutions\\drawing_utils.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mp_drawing.DrawingSpec??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8404d1da-04b9-4693-9e03-15d5963b956b",
   "metadata": {},
   "source": [
    "# Joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0793504b-99c7-497c-9ad3-eccdd7835758",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78854844-b16b-45a0-bcbf-4d0d979a50b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "689ad88f-70ee-4349-ac76-18c934962738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseLandmark.NOSE\n",
      "PoseLandmark.LEFT_EYE_INNER\n",
      "PoseLandmark.LEFT_EYE\n",
      "PoseLandmark.LEFT_EYE_OUTER\n",
      "PoseLandmark.RIGHT_EYE_INNER\n",
      "PoseLandmark.RIGHT_EYE\n",
      "PoseLandmark.RIGHT_EYE_OUTER\n",
      "PoseLandmark.LEFT_EAR\n",
      "PoseLandmark.RIGHT_EAR\n",
      "PoseLandmark.MOUTH_LEFT\n",
      "PoseLandmark.MOUTH_RIGHT\n",
      "PoseLandmark.LEFT_SHOULDER\n",
      "PoseLandmark.RIGHT_SHOULDER\n",
      "PoseLandmark.LEFT_ELBOW\n",
      "PoseLandmark.RIGHT_ELBOW\n",
      "PoseLandmark.LEFT_WRIST\n",
      "PoseLandmark.RIGHT_WRIST\n",
      "PoseLandmark.LEFT_PINKY\n",
      "PoseLandmark.RIGHT_PINKY\n",
      "PoseLandmark.LEFT_INDEX\n",
      "PoseLandmark.RIGHT_INDEX\n",
      "PoseLandmark.LEFT_THUMB\n",
      "PoseLandmark.RIGHT_THUMB\n",
      "PoseLandmark.LEFT_HIP\n",
      "PoseLandmark.RIGHT_HIP\n",
      "PoseLandmark.LEFT_KNEE\n",
      "PoseLandmark.RIGHT_KNEE\n",
      "PoseLandmark.LEFT_ANKLE\n",
      "PoseLandmark.RIGHT_ANKLE\n",
      "PoseLandmark.LEFT_HEEL\n",
      "PoseLandmark.RIGHT_HEEL\n",
      "PoseLandmark.LEFT_FOOT_INDEX\n",
      "PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65f68a09-50e8-4c34-8390-40a25187431b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973975419998169"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d52fa800-409a-4cc8-b80f-5152fcf9d992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.874142647\n",
       "y: 1.29759288\n",
       "z: -0.406385362\n",
       "visibility: 0.204050034"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77378a2e-9534-4c04-978c-836243c04b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.884648204\n",
       "y: 1.66814542\n",
       "z: -0.820594907\n",
       "visibility: 0.051609993"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2655b6-4411-4dd5-84ba-35a4b283a755",
   "metadata": {},
   "source": [
    "# Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19d6ee94-4e04-4ac5-83b4-a3cf41684a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcefc83c-08c1-4179-aa02-8b01a7c31778",
   "metadata": {},
   "outputs": [],
   "source": [
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20ac0496-db60-4db1-90e3-35ece30d6058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7765820622444153, 0.8729833960533142],\n",
       " [0.8741426467895508, 1.2975928783416748],\n",
       " [0.8846482038497925, 1.6681454181671143])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoulder, elbow, wrist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db264073-d078-40ad-a051-0ad963b54240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7765820622444153, 0.8729833960533142],\n",
       " [0.8741426467895508, 1.2975928783416748],\n",
       " [0.8846482038497925, 1.6681454181671143])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoulder, elbow, wrist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f4cf35f-3009-47e8-8aeb-8752ac0f585f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(559, 622)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(np.multiply(elbow, [640, 480]).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec7d2fa3-837b-4974-8fd1-a21028fe5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate angle\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(angle), \n",
    "                           tuple(np.multiply(elbow, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da38684-7257-4187-a91c-08d248196517",
   "metadata": {},
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99266fd7-4fc7-4cdc-b593-d05137d3cc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Curl counter variables\n",
    "counter = 0 \n",
    "stage = None\n",
    "\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Resize frame\n",
    "        frame = cv2.resize(frame, (1280, 960))\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate angle\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(angle), \n",
    "                           tuple(np.multiply(elbow, [1280, 960]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if angle > 160:\n",
    "                stage = \"down\"\n",
    "            if angle < 30 and stage =='down':\n",
    "                stage=\"up\"\n",
    "                counter +=1\n",
    "                print(counter)\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render curl counter\n",
    "        # Setup status box\n",
    "        #cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n",
    "        \n",
    "        # Rep data\n",
    "        #cv2.putText(image, 'REPS', (15,12), \n",
    "        #            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        #cv2.putText(image, str(counter), \n",
    "        #            (10,60), \n",
    "        #            cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Stage data\n",
    "        #cv2.putText(image, 'STAGE', (65,12), \n",
    "        #            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        #cv2.putText(image, stage, \n",
    "        #            (60,60), \n",
    "        #            cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f30782-243f-42d2-aacd-4f7f77bcebe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
